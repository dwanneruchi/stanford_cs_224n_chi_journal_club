{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First notebook: \n",
    "\n",
    "- Looks like we are going to build a feed-forward Neural Network for Dependence parsing\n",
    "\n",
    "- Doing experimentation in this notebook\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "CS224N 2019-20: Homework 3\n",
    "parser_model.py: Feed-Forward Neural Network for Dependency Parsing\n",
    "Sahil Chopra <schopra8@stanford.edu>\n",
    "Haoshen Hong <haoshen@stanford.edu>\n",
    "\"\"\"\n",
    "import pickle\n",
    "import os\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        \n",
    "class ParserModel(nn.Module):\n",
    "    \"\"\" Feedforward neural network with an embedding layer and single hidden layer.\n",
    "    The ParserModel will predict which transition should be applied to a\n",
    "    given partial parse configuration.\n",
    "\n",
    "    PyTorch Notes:\n",
    "        - Note that \"ParserModel\" is a subclass of the \"nn.Module\" class. In PyTorch all neural networks\n",
    "            are a subclass of this \"nn.Module\".\n",
    "        - The \"__init__\" method is where you define all the layers and their respective parameters\n",
    "            (embedding layers, linear layers, dropout layers, etc.).\n",
    "        - \"__init__\" gets automatically called when you create a new instance of your class, e.g.\n",
    "            when you write \"m = ParserModel()\".\n",
    "        - Other methods of ParserModel can access variables that have \"self.\" prefix. Thus,\n",
    "            you should add the \"self.\" prefix layers, values, etc. that you want to utilize\n",
    "            in other ParserModel methods.\n",
    "        - For further documentation on \"nn.Module\" please see https://pytorch.org/docs/stable/nn.html.\n",
    "    \"\"\"\n",
    "    def __init__(self, embeddings, n_features=36,\n",
    "        hidden_size=200, n_classes=3, dropout_prob=0.5):\n",
    "        \"\"\" Initialize the parser model.\n",
    "\n",
    "        @param embeddings (Tensor): word embeddings (num_words, embedding_size)\n",
    "        @param n_features (int): number of input features\n",
    "        @param hidden_size (int): number of hidden units\n",
    "        @param n_classes (int): number of output classes\n",
    "        @param dropout_prob (float): dropout probability\n",
    "        \"\"\"\n",
    "        super(ParserModel, self).__init__() # we can access methods & such from ParserModel\n",
    "        self.n_features = n_features\n",
    "        self.n_classes = n_classes\n",
    "        self.dropout_prob = dropout_prob\n",
    "        self.embed_size = embeddings.shape[1]\n",
    "        self.hidden_size = hidden_size\n",
    "        self.pretrained_embeddings = nn.Embedding(embeddings.shape[0], self.embed_size)\n",
    "        self.pretrained_embeddings.weight = nn.Parameter(torch.tensor(embeddings))\n",
    "\n",
    "        ### YOUR CODE HERE (~5 Lines)\n",
    "        ### TODO:\n",
    "        ###     1) Construct `self.embed_to_hidden` linear layer, initializing the weight matrix\n",
    "        ###         with the `nn.init.xavier_uniform_` function with `gain = 1` (default)\n",
    "        \n",
    "        self.embed_to_hidden = nn.Linear(self.n_features * self.embed_size, self.hidden_size) # what tensor to pass? (dim_in, hidden_size)\n",
    "        \n",
    "        # TODO: Refresh memory on this - should I be doing embed x hidden? or is it embed x feat x hidden?\n",
    "        # Will automatically build out the proper weight & bias terms, but we want weight\n",
    "        nn.init.xavier_uniform_(self.embed_to_hidden.weight, gain = 1) # initialize\n",
    "        \n",
    "        ###     2) Construct `self.dropout` layer.\n",
    "        self.dropout = nn.Dropout(self.dropout_prob) # we refer to our input value\n",
    "        \n",
    "        ###     3) Construct `self.hidden_to_logits` linear layer, initializing the weight matrix\n",
    "        ###         with the `nn.init.xavier_uniform_` function with `gain = 1` (default)\n",
    "        ###\n",
    "        self.hidden_to_logits = nn.Linear(self.hidden_size, self.n_classes) # what tensor to pass? (hidden, num_classes)\n",
    "        nn.init.xavier_uniform_(self.hidden_to_logits.weight, gain = 1) # initialize weight only\n",
    "        \n",
    "        ### Note: Here, we use Xavier Uniform Initialization for our Weight initialization.\n",
    "        ###         It has been shown empirically, that this provides better initial weights\n",
    "        ###         for training networks than random uniform initialization.\n",
    "        ###         For more details checkout this great blogpost:\n",
    "        ###             http://andyljones.tumblr.com/post/110998971763/an-explanation-of-xavier-initialization \n",
    "        ### Hints:\n",
    "        ###     - After you create a linear layer you can access the weight\n",
    "        ###       matrix via:\n",
    "        ###         linear_layer.weight\n",
    "        ###\n",
    "        ### Please see the following docs for support:\n",
    "        ###     Linear Layer: https://pytorch.org/docs/stable/nn.html#torch.nn.Linear\n",
    "        ###     Xavier Init: https://pytorch.org/docs/stable/nn.html#torch.nn.init.xavier_uniform_\n",
    "        ###     Dropout: https://pytorch.org/docs/stable/nn.html#torch.nn.Dropout\n",
    "\n",
    "\n",
    "        ### END YOUR CODE\n",
    "\n",
    "    def embedding_lookup(self, t):\n",
    "        \"\"\" Utilize `self.pretrained_embeddings` to map input `t` from input tokens (integers)\n",
    "            to embedding vectors.\n",
    "\n",
    "            PyTorch Notes:\n",
    "                - `self.pretrained_embeddings` is a torch.nn.Embedding object that we defined in __init__\n",
    "                - Here `t` is a tensor where each row represents a list of features. Each feature is represented by an integer (input token).\n",
    "                - In PyTorch the Embedding object, e.g. `self.pretrained_embeddings`, allows you to\n",
    "                    go from an index to embedding. Please see the documentation (https://pytorch.org/docs/stable/nn.html#torch.nn.Embedding)\n",
    "                    to learn how to use `self.pretrained_embeddings` to extract the embeddings for your tensor `t`.\n",
    "\n",
    "            @param t (Tensor): input tensor of tokens (batch_size, n_features)\n",
    "\n",
    "            @return x (Tensor): tensor of embeddings for words represented in t\n",
    "                                (batch_size, n_features * embed_size)\n",
    "        \"\"\"\n",
    "        ### YOUR CODE HERE (~1-3 Lines)\n",
    "        ### TODO:\n",
    "        ###     1) Use `self.pretrained_embeddings` to lookup the embeddings for the input tokens in `t`.\n",
    "        \n",
    "        # we pass in a tensor of features stored as integers \n",
    "        # the embeddings is of size (vocab, vector_size) where vector_size just represents our representational features\n",
    "        # pretrained_embeddings class can handle recimport torch\n",
    "        \n",
    "        \"\"\"\n",
    "        import torch\n",
    "        from torch import nn\n",
    "        embedding = nn.Embedding(1000,128)\n",
    "        test_case = embedding(torch.LongTensor([3,4]))\n",
    "        assert embedding(torch.LongTensor([3])).sum().item() == test_case[0].sum().item() # we got the proper val\n",
    "        \n",
    "        # this would return a tensor with embeddings for the 3rd & 4th word from vocab of 1000 in positions 0 & 1\n",
    "        # i then just sum up embeddings to confirm\n",
    "        # info: https://stackoverflow.com/questions/50747947/embedding-in-pytorch\n",
    "        \"\"\"\n",
    "        x = self.pretrained_embeddings(t)\n",
    "        \n",
    "        \n",
    "        ###     2) After you apply the embedding lookup, you will have a tensor shape (batch_size, n_features, embedding_size).\n",
    "        ###         Use the tensor `view` method to reshape the embeddings tensor to (batch_size, n_features * embedding_size)\n",
    "        ###\n",
    "        ### Note: In order to get batch_size, you may need use the tensor .size() function:\n",
    "        ###         https://pytorch.org/docs/stable/tensors.html#torch.Tensor.size\n",
    "        ###\n",
    "        \n",
    "        # helpful: https://stackoverflow.com/questions/42479902/how-does-the-view-method-work-in-pytorch\n",
    "        # 3D tensor right now: (b, feat, embedding dim) -> (b, f * e)\n",
    "        # use .size() ----> test_case.size()[0], test_case.size()[1] * test_case.size()[2]\n",
    "        x = x.view(x.size()[0], x.size()[1] * x.size()[2])\n",
    "        \n",
    "        \n",
    "        # ensure that our X has same number of rows as the input tensor \n",
    "        assert x.size()[0] == t.size()[0]\n",
    "        \n",
    "        # ensure our x has the same num of cols as feat * embedding dim\n",
    "        assert x.size()[1] == t.size()[1] * self.pretrained_embeddings.weight.size()[1]\n",
    "        \n",
    "        \n",
    "        ###  Please see the following docs for support:\n",
    "        ###     Embedding Layer: https://pytorch.org/docs/stable/nn.html#torch.nn.Embedding\n",
    "        ###     View: https://pytorch.org/docs/stable/tensors.html#torch.Tensor.view\n",
    "\n",
    "\n",
    "        ### END YOUR CODE\n",
    "        return x\n",
    "\n",
    "\n",
    "    def forward(self, t):\n",
    "        \"\"\" Run the model forward.\n",
    "\n",
    "            Note that we will not apply the softmax function here because it is included in the loss function nn.CrossEntropyLoss\n",
    "\n",
    "            PyTorch Notes:\n",
    "                - Every nn.Module object (PyTorch model) has a `forward` function.\n",
    "                - When you apply your nn.Module to an input tensor `t` this function is applied to the tensor.\n",
    "                    For example, if you created an instance of your ParserModel and applied it to some `t` as follows,\n",
    "                    the `forward` function would called on `t` and the result would be stored in the `output` variable:\n",
    "                        model = ParserModel()\n",
    "                        output = model(t) # this calls the forward function\n",
    "                - For more details checkout: https://pytorch.org/docs/stable/nn.html#torch.nn.Module.forward\n",
    "\n",
    "        @param t (Tensor): input tensor of tokens (batch_size, n_features)\n",
    "\n",
    "        @return logits (Tensor): tensor of predictions (output after applying the layers of the network)\n",
    "                                 without applying softmax (batch_size, n_classes)\n",
    "        \"\"\"\n",
    "        ###  YOUR CODE HERE (~3-5 lines)\n",
    "        ### TODO:\n",
    "        ###     1) Apply `self.embedding_lookup` to `t` to get the embeddings\n",
    "        \n",
    "        # create output of our embedding matrix called \"embeddings\"\n",
    "        self.embeddings = self.embedding_lookup(t)\n",
    "        \n",
    "        ###     2) Apply `embed_to_hidden` linear layer to the embeddings\n",
    "        \n",
    "        # we are now passing our (batch, 1080 feat) through weights to build our 'z' (output prior to passing into activation\n",
    "        # this is just W^T * X + b \n",
    "        # adding a line to convert embeddings to float - my testing was failing probably due to my input values being integers\n",
    "        self.z =  self.embed_to_hidden(self.embeddings.float())\n",
    "        \n",
    "        \n",
    "        ###     3) Apply relu non-linearity to the output of step 2 to get the hidden units.\n",
    "        # looks like this is in the functional portion of torch.nn from documentaiton\n",
    "        self.a = F.relu(self.z)\n",
    "        \n",
    "        ###     4) Apply dropout layer to the output of step 3.\n",
    "        # we now have a dropout layer to pass embeddings through\n",
    "        # rrather, pass a through\n",
    "        # need to recall that our weights will be scaled according to our likelihood of being dropped out \n",
    "        # this handles proper signal output\n",
    "        self.drop_a = self.dropout(self.a)\n",
    "        \n",
    "        ###     5) Apply `hidden_to_logits` layer to the output of step 4 to get the logits.\n",
    "        ###\n",
    "        \n",
    "        self.z2 = self.hidden_to_logits(self.drop_a) # this will eventually be passed to a softmax layer\n",
    "        \n",
    "        ### Note: We do not apply the softmax to the logits here, because\n",
    "        ### the loss function (torch.nn.CrossEntropyLoss) applies it more efficiently.\n",
    "        ###\n",
    "        ### Please see the following docs for support:\n",
    "        ###     ReLU: https://pytorch.org/docs/stable/nn.html?highlight=relu#torch.nn.functional.relu\n",
    "\n",
    "\n",
    "        ### END YOUR CODE\n",
    "        #return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = nn.Embedding(1000,128)\n",
    "test_case = embedding(torch.LongTensor([3,4]))\n",
    "assert embedding(torch.LongTensor([3])).sum().item() == test_case[0].sum().item() # we got the proper val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 128])"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_case.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 30)\n",
      "[[0.42389749 0.91604898 0.7669048  0.74621228 0.79671346 0.17066938\n",
      "  0.6062048  0.32924545 0.03539561 0.23327253 0.31414712 0.14020396\n",
      "  0.59638958 0.155752   0.29738047 0.94842817 0.09997582 0.6856703\n",
      "  0.06868365 0.33907189 0.70830388 0.64982319 0.1295096  0.42927301\n",
      "  0.27109608 0.32810999 0.38914617 0.15096077 0.86548612 0.1461038 ]]\n"
     ]
    }
   ],
   "source": [
    "# building embeddings that are 100 x 30 --embeddings will be overwritten\n",
    "embeddings = np.random.random_sample((100, 30)).astype(dtype = 'float64')\n",
    "\n",
    "# convert to float\n",
    "\n",
    "print(embeddings.shape) # 100 x 30 ---> 100 inputs, each with 30 vals\n",
    "print(embeddings[1:2,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate: \n",
    "model = ParserModel(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=1080, out_features=200, bias=True)"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.embed_to_hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8641, 0.9854, 0.7399, 0.8110, 0.4895, 0.0596, 0.2673, 0.4251, 0.5998,\n",
       "         0.0398, 0.8565, 0.6324, 0.5488, 0.3934, 0.6756, 0.8744, 0.4459, 0.1679,\n",
       "         0.8272, 0.1401, 0.1169, 0.8471, 0.7919, 0.7971, 0.1145, 0.8239, 0.9562,\n",
       "         0.8513, 0.5928, 0.3438]], dtype=torch.float64,\n",
       "       grad_fn=<EmbeddingBackward>)"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.pretrained_embeddings(torch.LongTensor([3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[0.4203, 0.5863, 0.4584,  ..., 0.7357, 0.4661, 0.1332],\n",
       "        [0.4239, 0.9160, 0.7669,  ..., 0.1510, 0.8655, 0.1461],\n",
       "        [0.6994, 0.8283, 0.3989,  ..., 0.9111, 0.8091, 0.1646],\n",
       "        ...,\n",
       "        [0.0866, 0.1870, 0.9377,  ..., 0.8824, 0.6490, 0.4211],\n",
       "        [0.3144, 0.9208, 0.4147,  ..., 0.7599, 0.9560, 0.9084],\n",
       "        [0.3581, 0.1411, 0.7591,  ..., 0.4304, 0.4998, 0.9074]],\n",
       "       dtype=torch.float64, requires_grad=True)"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.pretrained_embeddings.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We input a tensor of word indices of size: 4 samples, and 36 words each\n",
      "Our output tensor is: torch.Size([4, 1080])\n"
     ]
    }
   ],
   "source": [
    "# build indices tensor\n",
    "inds = torch.randint(0, 100, (4, 36), dtype=torch.long)\n",
    "print(f\"We input a tensor of word indices of size: {inds.size()[0]} samples, and {inds.size()[1]} words each\")\n",
    "output = model.embedding_lookup(inds)\n",
    "# our output: should be (batch, word * embed dim)\n",
    "print(f\"Our output tensor is: {output.size()}\") # makes sense, we are converting a word into 30 features, so each row is a long vector os 36 * 30, 1080"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.forward(inds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-relu output: tensor([ 2.0081e-01,  3.6685e-01,  9.5539e-01,  1.4285e-02,  6.9633e-01,\n",
      "         7.6659e-01, -5.8838e-02, -1.5154e-01, -2.1040e-02,  1.1938e+00,\n",
      "        -6.4937e-03,  5.5015e-05, -8.2114e-01,  8.1163e-02,  5.3801e-01,\n",
      "        -6.1641e-01,  7.8655e-01, -5.2092e-01, -1.6474e+00,  2.6407e-01],\n",
      "       grad_fn=<SliceBackward>)\n",
      "Post-relu output: tensor([2.0081e-01, 3.6685e-01, 9.5539e-01, 1.4285e-02, 6.9633e-01, 7.6659e-01,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1938e+00, 0.0000e+00, 5.5015e-05,\n",
      "        0.0000e+00, 8.1163e-02, 5.3801e-01, 0.0000e+00, 7.8655e-01, 0.0000e+00,\n",
      "        0.0000e+00, 2.6407e-01], grad_fn=<SliceBackward>)\n"
     ]
    }
   ],
   "source": [
    "# let's confirm relu worked - looks good\n",
    "print(f'Pre-relu output: {model.z[0][:20]}')\n",
    "print(f'Post-relu output: {model.a[0][:20]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4.0162e-01, 7.3369e-01, 1.9108e+00, 2.8570e-02, 0.0000e+00, 1.5332e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1003e-04,\n",
       "        0.0000e+00, 1.6233e-01, 0.0000e+00, 0.0000e+00, 1.5731e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00], grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.drop_a[0][:20] # some of our values were randoly flagged as 0? looks like it doubles weight of others?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.,  0.,  0.,  0., 10., 12.])\n",
      "tensor([ 0.,  0.,  0.,  0., 50.,  0.])\n"
     ]
    }
   ],
   "source": [
    "# understanding dropout: randomly selects weights to set to 0\n",
    "# helpful: https://discuss.pytorch.org/t/unclear-behaviour-of-dropout/22890/2\n",
    "# this will scale according to the dropout size...so dropout_p = 0.5, then we double the weight\n",
    "inp = torch.tensor([1.,2.,3.,4.,5.,6.])\n",
    "d2 = torch.nn.Dropout(0.5)\n",
    "print(d2(inp)) # scales 2x\n",
    "\n",
    "d10 = torch.nn.Dropout(0.9) # this is 1 - p, so our prob of being dropped is very high & we need to amplify weights out\n",
    "print(d10(inp)) # scales 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0161, -0.9356, -1.2237],\n",
      "        [ 0.1997,  0.2710,  0.0748],\n",
      "        [-0.6898,  0.5865,  0.8704],\n",
      "        [-1.0014,  1.4029,  1.3682]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "# checking our output for final layer: we initialized with 3 classes, and passed in 4 observations\n",
    "# our output at this point should be a : 4 x 3 tensorw, which has 3 preds per observations\n",
    "print(model.z2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
