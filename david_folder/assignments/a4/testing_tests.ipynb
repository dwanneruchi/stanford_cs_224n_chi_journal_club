{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import sys\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from docopt import docopt\n",
    "from typing import List, Tuple, Dict, Set, Union\n",
    "from tqdm import tqdm\n",
    "from utils import read_corpus, batch_iter\n",
    "from vocab import Vocab, VocabEntry\n",
    "\n",
    "from nmt_model import NMT\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.utils\n",
    "\n",
    "#----------\n",
    "# CONSTANTS\n",
    "#----------\n",
    "BATCH_SIZE = 5\n",
    "EMBED_SIZE = 3\n",
    "HIDDEN_SIZE = 3\n",
    "DROPOUT_RATE = 0.0\n",
    "\n",
    "def reinitialize_layers(model):\n",
    "    \"\"\" Reinitialize the Layer Weights for Sanity Checks.\n",
    "    \"\"\"\n",
    "    def init_weights(m):\n",
    "        if type(m) == nn.Linear:\n",
    "            m.weight.data.fill_(0.3)\n",
    "            if m.bias is not None:\n",
    "                m.bias.data.fill_(0.1)\n",
    "        elif type(m) == nn.Embedding:\n",
    "            m.weight.data.fill_(0.15)\n",
    "        elif type(m) == nn.Dropout:\n",
    "            nn.Dropout(DROPOUT_RATE)\n",
    "    with torch.no_grad():\n",
    "        model.apply(init_weights)\n",
    "\n",
    "\n",
    "def generate_outputs(model, source, target, vocab):\n",
    "    \"\"\" Generate outputs.\n",
    "    \"\"\"\n",
    "    print (\"-\"*80)\n",
    "    print(\"Generating Comparison Outputs\")\n",
    "    reinitialize_layers(model)\n",
    "\n",
    "    # Compute sentence lengths\n",
    "    source_lengths = [len(s) for s in source]\n",
    "\n",
    "    # Convert list of lists into tensors\n",
    "    source_padded = model.vocab.src.to_input_tensor(source, device=model.device)\n",
    "    target_padded = model.vocab.tgt.to_input_tensor(target, device=model.device)\n",
    "\n",
    "    # Run the model forward\n",
    "    with torch.no_grad():\n",
    "        enc_hiddens, dec_init_state = model.encode(source_padded, source_lengths)\n",
    "        enc_masks = model.generate_sent_masks(enc_hiddens, source_lengths)\n",
    "        combined_outputs = model.decode(enc_hiddens, enc_masks, dec_init_state, target_padded)\n",
    "\n",
    "    # Save Tensors to disk\n",
    "    torch.save(enc_hiddens, './sanity_check_en_es_data/enc_hiddens.pkl')\n",
    "    torch.save(dec_init_state, './sanity_check_en_es_data/dec_init_state.pkl') \n",
    "    torch.save(enc_masks, './sanity_check_en_es_data/enc_masks.pkl')\n",
    "    torch.save(combined_outputs, './sanity_check_en_es_data/combined_outputs.pkl')\n",
    "\n",
    "\n",
    "def question_1d_sanity_check(model, src_sents, tgt_sents, vocab):\n",
    "    \"\"\" Sanity check for question 1d. \n",
    "        Compares student output to that of model with dummy data.\n",
    "    \"\"\"\n",
    "    print(\"Running Sanity Check for Question 1d: Encode\")\n",
    "    print (\"-\"*80)\n",
    "\n",
    "    # Configure for Testing\n",
    "    reinitialize_layers(model)\n",
    "    source_lengths = [len(s) for s in src_sents]\n",
    "    source_padded = model.vocab.src.to_input_tensor(src_sents, device=model.device)\n",
    "\n",
    "    # Load Outputs\n",
    "    enc_hiddens_target = torch.load('./sanity_check_en_es_data/enc_hiddens.pkl')\n",
    "    dec_init_state_target = torch.load('./sanity_check_en_es_data/dec_init_state.pkl')\n",
    "\n",
    "    # Test\n",
    "    with torch.no_grad():\n",
    "        enc_hiddens_pred, dec_init_state_pred = model.encode(source_padded, source_lengths)\n",
    "    assert(np.allclose(enc_hiddens_target.numpy(), enc_hiddens_pred.numpy())), \"enc_hiddens is incorrect: it should be:\\n {} but is:\\n{}\".format(enc_hiddens_target, enc_hiddens_pred)\n",
    "    print(\"enc_hiddens Sanity Checks Passed!\")\n",
    "    assert(np.allclose(dec_init_state_target[0].numpy(), dec_init_state_pred[0].numpy())), \"dec_init_state[0] is incorrect: it should be:\\n {} but is:\\n{}\".format(dec_init_state_target[0], dec_init_state_pred[0])\n",
    "    print(\"dec_init_state[0] Sanity Checks Passed!\")\n",
    "    assert(np.allclose(dec_init_state_target[1].numpy(), dec_init_state_pred[1].numpy())), \"dec_init_state[1] is incorrect: it should be:\\n {} but is:\\n{}\".format(dec_init_state_target[1], dec_init_state_pred[1])\n",
    "    print(\"dec_init_state[1] Sanity Checks Passed!\")\n",
    "    print (\"-\"*80)\n",
    "    print(\"All Sanity Checks Passed for Question 1d: Encode!\")\n",
    "    print (\"-\"*80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Check Python & PyTorch Versions\n",
    "assert (sys.version_info >= (3, 5)), \"Please update your installation of Python to version >= 3.5\"\n",
    "\n",
    "# I already know I don't have proper install \n",
    "#assert(torch.__version__ == \"1.0.0\"), \"Please update your installation of PyTorch. You have {} and you should have version 1.0.0\".format(torch.__version__)\n",
    "\n",
    "# Seed the Random Number Generators\n",
    "seed = 1234\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "np.random.seed(seed * 13 // 7)\n",
    "\n",
    "# Load training data & vocabulary\n",
    "train_data_src = read_corpus('./sanity_check_en_es_data/train_sanity_check.es', 'src')\n",
    "train_data_tgt = read_corpus('./sanity_check_en_es_data/train_sanity_check.en', 'tgt')\n",
    "train_data = list(zip(train_data_src, train_data_tgt))\n",
    "\n",
    "for src_sents, tgt_sents in batch_iter(train_data, batch_size=BATCH_SIZE, shuffle=True):\n",
    "    src_sents = src_sents\n",
    "    tgt_sents = tgt_sents\n",
    "    break\n",
    "vocab = Vocab.load('./sanity_check_en_es_data/vocab_sanity_check.json') \n",
    "\n",
    "# Create NMT Model\n",
    "model = NMT(\n",
    "    embed_size=EMBED_SIZE,\n",
    "    hidden_size=HIDDEN_SIZE,\n",
    "    dropout_rate=DROPOUT_RATE,\n",
    "    vocab=vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Moving into first test: `.encode()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Sanity Check for Question 1d: Encode\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"Running Sanity Check for Question 1d: Encode\")\n",
    "print (\"-\"*80)\n",
    "\n",
    "# Configure for Testing\n",
    "reinitialize_layers(model)\n",
    "source_lengths = [len(s) for s in src_sents]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some error here....fixed by copying utils...so my utils is broken for some reason....\n",
    "source_padded = model.vocab.src.to_input_tensor(src_sents, device=model.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Outputs\n",
    "enc_hiddens_target = torch.load('./sanity_check_en_es_data/enc_hiddens.pkl')\n",
    "dec_init_state_target = torch.load('./sanity_check_en_es_data/dec_init_state.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "with torch.no_grad():\n",
    "    enc_hiddens_pred, dec_init_state_pred = model.encode(source_padded, source_lengths)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 20, 6])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_hiddens_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 20, 6])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_hiddens_target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enc_hiddens Sanity Checks Passed!\n"
     ]
    }
   ],
   "source": [
    "assert(np.allclose(enc_hiddens_target.numpy(), enc_hiddens_pred.numpy())), \"enc_hiddens is incorrect: it should be:\\n {} but is:\\n{}\".format(enc_hiddens_target, enc_hiddens_pred)\n",
    "print(\"enc_hiddens Sanity Checks Passed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dec_init_state[0] Sanity Checks Passed!\n",
      "dec_init_state[1] Sanity Checks Passed!\n",
      "--------------------------------------------------------------------------------\n",
      "All Sanity Checks Passed for Question 1d: Encode!\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "assert(np.allclose(dec_init_state_target[0].numpy(), dec_init_state_pred[0].numpy())), \"dec_init_state[0] is incorrect: it should be:\\n {} but is:\\n{}\".format(dec_init_state_target[0], dec_init_state_pred[0])\n",
    "print(\"dec_init_state[0] Sanity Checks Passed!\")\n",
    "assert(np.allclose(dec_init_state_target[1].numpy(), dec_init_state_pred[1].numpy())), \"dec_init_state[1] is incorrect: it should be:\\n {} but is:\\n{}\".format(dec_init_state_target[1], dec_init_state_pred[1])\n",
    "print(\"dec_init_state[1] Sanity Checks Passed!\")\n",
    "print (\"-\"*80)\n",
    "print(\"All Sanity Checks Passed for Question 1d: Encode!\")\n",
    "print (\"-\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Moving into second test: `.decode()`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
