{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from typing import List\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sents(sents, pad_token):\n",
    "    \"\"\" Pad list of sentences according to the longest sentence in the batch.\n",
    "    @param sents (list[list[str]]): list of sentences, where each sentence\n",
    "                                    is represented as a list of words\n",
    "    @param pad_token (str): padding token\n",
    "    @returns sents_padded (list[list[str]]): list of sentences where sentences shorter\n",
    "        than the max length sentence are padded out with the pad_token, such that\n",
    "        each sentences in the batch now has equal length.\n",
    "    \"\"\"\n",
    "    sents_padded = []\n",
    "\n",
    "    ### YOUR CODE HERE (~6 Lines)\n",
    "    \n",
    "    # first find max length of sentences\n",
    "    sent_lens = [len(unique_sents) for unique_sents in sents]\n",
    "    max_len = max(sent_lens)\n",
    "    \n",
    "    # we then iterate through each while len != max_len\n",
    "    for unique_sents in sents:\n",
    "        \n",
    "        while len(unique_sents) < max_len:\n",
    "            unique_sents.append(pad_token)\n",
    "        \n",
    "        # we then append outside of while loop: those that pass initially will be appended automatically\n",
    "        sents_padded.append(unique_sents)\n",
    "\n",
    "    ### END YOUR CODE\n",
    "    return sents_padded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Going to build a test for this: \n",
    "\n",
    "- if we have two sentences, one of length 3 and one of length 4, then what is expected output? \n",
    "\n",
    "    - \"my test sentence\"\n",
    "    - \"my second test sentence\"\n",
    "\n",
    "- expected output: \n",
    "\n",
    "    - \"my test sentence <pad_token>\" (does it matter if at end or beginning?)\n",
    "    - \"my second test sentence\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_token_test = '<PADDING>'\n",
    "\n",
    "test_sents = [\n",
    "    ['my', 'test', 'sentence'],\n",
    "    ['my', 'second','test', 'sentence'],\n",
    "    ['my', 'longer', 'third', 'test', 'sentence'],\n",
    "    ['my', 'longer', 'fourth', 'test', 'sentence']\n",
    "]\n",
    "\n",
    "test_ans = [\n",
    "    ['my', 'test', 'sentence', pad_token_test, pad_token_test],\n",
    "    ['my', 'second','test', 'sentence', pad_token_test],\n",
    "    ['my', 'longer', 'third', 'test', 'sentence'],\n",
    "    ['my', 'longer', 'fourth', 'test', 'sentence']\n",
    "]\n",
    "\n",
    "# run test: \n",
    "test_output = pad_sents(sents = test_sents, pad_token = pad_token_test)\n",
    "\n",
    "assert test_output == test_ans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sents(sents, pad_token):\n",
    "    \"\"\" Pad list of sentences according to the longest sentence in the batch.\n",
    "    @param sents (list[list[str]]): list of sentences, where each sentence\n",
    "                                    is represented as a list of words\n",
    "    @param pad_token (str): padding token\n",
    "    @returns sents_padded (list[list[str]]): list of sentences where sentences shorter\n",
    "        than the max length sentence are padded out with the pad_token, such that\n",
    "        each sentences in the batch now has equal length.\n",
    "    \"\"\"\n",
    "    sents_padded = []\n",
    "\n",
    "    ### YOUR CODE HERE (~6 Lines)\n",
    "    \n",
    "    longest = max([len(sent) for sent in sents])\n",
    "    sents_padded = list(map(lambda sent: sent+[pad_token]*(longest-len(sent)), sents))\n",
    "    ### END YOUR CODE\n",
    "\n",
    "    return sents_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_output_2 = pad_sents(sents = test_sents, pad_token = pad_token_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['my', 'test', 'sentence', '<PADDING>', '<PADDING>'],\n",
       " ['my', 'second', 'test', 'sentence', '<PADDING>'],\n",
       " ['my', 'longer', 'third', 'test', 'sentence'],\n",
       " ['my', 'longer', 'fourth', 'test', 'sentence']]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['my', 'test', 'sentence', '<PADDING>', '<PADDING>'],\n",
       " ['my', 'second', 'test', 'sentence', '<PADDING>'],\n",
       " ['my', 'longer', 'third', 'test', 'sentence'],\n",
       " ['my', 'longer', 'fourth', 'test', 'sentence']]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_output_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_output == test_output_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_corpus(file_path, source):\n",
    "    \"\"\" Read file, where each sentence is dilineated by a `\\n`.\n",
    "    @param file_path (str): path to file containing corpus\n",
    "    @param source (str): \"tgt\" or \"src\" indicating whether text\n",
    "        is of the source language or target language\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    for line in open(file_path):\n",
    "        sent = line.strip().split(' ')\n",
    "        # only append <s> and </s> to the target sentence\n",
    "        if source == 'tgt':\n",
    "            sent = ['<s>'] + sent + ['</s>']\n",
    "        data.append(sent)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def batch_iter(data, batch_size, shuffle=False):\n",
    "    \"\"\" Yield batches of source and target sentences reverse sorted by length (largest to smallest).\n",
    "    @param data (list of (src_sent, tgt_sent)): list of tuples containing source and target sentence\n",
    "    @param batch_size (int): batch size\n",
    "    @param shuffle (boolean): whether to randomly shuffle the dataset\n",
    "    \"\"\"\n",
    "    batch_num = math.ceil(len(data) / batch_size)\n",
    "    index_array = list(range(len(data)))\n",
    "\n",
    "    if shuffle:\n",
    "        np.random.shuffle(index_array)\n",
    "\n",
    "    for i in range(batch_num):\n",
    "        indices = index_array[i * batch_size: (i + 1) * batch_size]\n",
    "        examples = [data[idx] for idx in indices]\n",
    "\n",
    "        examples = sorted(examples, key=lambda e: len(e[0]), reverse=True)\n",
    "        src_sents = [e[0] for e in examples]\n",
    "        tgt_sents = [e[1] for e in examples]\n",
    "\n",
    "        yield src_sents, tgt_sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
